# This is the main configuration file for the application.
# ~~~~~

# Secret key
# ~~~~~
# The secret key is used to secure cryptographics functions.
# If you deploy your application to several instances be sure to use the same key!
application.secret="Yf]0bsdO2ckhJd]^sQ^IPISElBrfy<XWdTWukRwJK8KKc3rFG>Cn;nnaX:N/=R1<"

# The application languages
# ~~~~~
application.langs="en"

# Global object class
# ~~~~~
# Define the Global object class for this application.
# Defaults to Global in the root package.
# application.global=my.Global

# Router
# ~~~~~
# Define the Router object to use for this application.
# This router will be looked up first when the application is starting up,
# so make sure this is the entry point.
# Furthermore, it's assumed your route file is named properly.
# So for an application router like `my.application.Router`,
# you may need to define a router file `conf/my.application.routes`.
# Default to Routes in the root package (and conf/routes)
# application.router=my.application.Routes

# Database configuration
# ~~~~~
# You can declare as many datasources as you want.
# By convention, the default datasource is named `default`
#
# db.default.driver=org.h2.Driver
# db.default.url="jdbc:h2:mem:play"
# db.default.user=sa
# db.default.password=""

# Evolutions
# ~~~~~
# You can disable evolutions if needed
# evolutionplugin=disabled

# Logger
# ~~~~~
# You can also configure logback (http://logback.qos.ch/), by providing a logger.xml file in the conf directory .

# Root logger:
logger.root=ERROR

# Logger used by the framework:
logger.play=INFO

# Logger provided to your application:
logger.application=DEBUG

# Uncomment this for the most verbose Akka debugging:
#akka {
#    loglevel = "DEBUG"
#    actor {
#        debug {
#            receive = on
#            autoreceive = on
#            lifecycle = on
#        }
#    }
#}

default.stocks=["GOOG", "AAPL", "ORCL"]

sentiment.url="http://text-processing.com/api/sentiment/"
tweet.url="http://twitter-search-proxy.herokuapp.com/search/tweets?q=%%24%s"

#This is the stuff which I had to add
akka {
  #extensions = ["kamon.metric.Metrics", "kamon.system.SystemMetrics", "kamon.logreporter.LogReporter", "kamon.statsd.StatsD"]
  #don't need this anymore (I think)

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = INFO
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
}

# Kamon Metrics
# ~~~~~~~~~~~~~~

kamon {

  log-reporter {
    #need this is a placeholder

  }

  akka {
    #write-actor-info-location = "/Users/tshull7/centostemp/test"
  }


  metric {
    #don't this so that information does not get in the way
    tick-interval = 10 seconds
    filters{ 
        akka-actor {
          includes = [ "**" ]
        }
        akka-router {
          includes = [ "**" ]
        }
        akka-dispatcher {
          includes = [ "**" ]
        }
        actor {
            includes = ["**"]
            excludes = []
        }

      #{
      #  trace {
      #    includes = [ "*" ]
      #    excludes = []
      #  }
      #}
    }
  }
  
  # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  statsd {
    # Hostname and port in which your StatsD is running. Remember that StatsD packets are sent using UDP and
    # setting unreachable hosts and/or not open ports wont be warned by the Kamon, your data wont go anywhere.
    #hostname = "127.0.0.1"
    hostname = "192.168.59.103"
    port = 8125

    # Interval between metrics data flushes to StatsD. It's value must be equal or greater than the
    # kamon.metrics.tick-interval setting.
    #flush-interval = 1 second

    # Max packet size for UDP metrics data sent to StatsD.
    max-packet-size = 1024 bytes

    # Subscription patterns used to select which metrics will be pushed to StatsD. Note that first, metrics
    # collection for your desired entities must be activated under the kamon.metrics.filters settings.
    includes {
      actor       = [ "*" ]
      trace       = [ "*" ]
      dispatcher  = [ "*" ]
    }

    #not sure if this will help
    report-system-metrics = true

    simple-metric-key-generator {
      # Application prefix for all metrics pushed to StatsD. The default namespacing scheme for metrics follows
      # this pattern:
      #    application.host.entity.entity-name.metric-name
      application = "example"
      hostname-override = "macpro"
    }
  }
}
